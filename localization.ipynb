{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g5allA7N47RG",
    "outputId": "29c71e2e-65d7-4f85-9675-89f7c5c10082"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Fn\n",
    "from time import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.io.image import read_image\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, RandomCrop,ToTensor, Normalize, Grayscale, RandomRotation\n",
    "from torchvision.transforms.v2 import  RandomResize\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "from torchvision.io.image import read_image,write_png\n",
    "from scipy.io import loadmat,savemat\n",
    "from skimage.draw import line\n",
    "from skimage.morphology import thin,medial_axis,skeletonize\n",
    "from scipy import ndimage\n",
    "from skimage import measure\n",
    "from MSLNet import log2file\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "try:\n",
    "    from torchvision.transforms import InterpolationMode\n",
    "    BICUBIC = InterpolationMode.BICUBIC\n",
    "except ImportError:\n",
    "    BICUBIC = Image.BICUBIC # resize the input image using bicubic interpolation, producing a smoother result compared to other interpolation methods like device = torch.device(\"cuda\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#device = 'cpu'\n",
    "print(device)\n",
    "def load_mask(path,name):\n",
    "    t=ToTensor()\n",
    "    x = t(Image.open(path+name+'.png'))\n",
    "    return x.squeeze(0)\n",
    "    \n",
    "def load_mask1(path,name):\n",
    "    yi=np.load(path+'masks/'+name+'.npy')\n",
    "    return torch.tensor(yi>0).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='d:/datasets/cathaction/'\n",
    "with open(path+'train.txt', 'r') as f:\n",
    "    train = f.read().splitlines()\n",
    "with open(path+'test.txt', 'r') as f:\n",
    "    test = f.read().splitlines()\n",
    "print(len(train),len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import linear_sum_assignment\n",
    "from percgrouping import draw, extractCurves, merge_curves, removeshortcurves, draw_cvs\n",
    "\n",
    "def load_image(name):\n",
    "    t=ToTensor()\n",
    "    x = t(Image.open(name))\n",
    "    return x\n",
    "\n",
    "def save_result(name,im):\n",
    "    im[im<=0]=0\n",
    "    im[im >= 255] = 255\n",
    "    write_png(im.unsqueeze(0).to(torch.uint8).cpu(),name)     \n",
    "\n",
    "def iou1(a,b):\n",
    "    \"\"\"\n",
    "    Function to get the IOU between two 1D-tensors\n",
    "    \"\"\"\n",
    "    io=torch.sum(a*b)/(torch.sum(torch.max(a,b))+0.00001)\n",
    "    return io\n",
    "\n",
    "def Dice(a,b):\n",
    "    return 2*torch.sum(a*b)/(torch.sum(a)+torch.sum(b))\n",
    "    \n",
    "def precision(a,dy):\n",
    "    ndet=np.sum(a) # detections\n",
    "    ncdet=np.sum(a*dy) \n",
    "    prec=ncdet/(ndet+0.00001)\n",
    "    return prec.item()\n",
    "\n",
    "def recall(dr,y):\n",
    "    npos=np.sum(y>0).item() # positives\n",
    "    npdet=np.sum((y*dr)>0).item() # detected positives, with detection at dist <=2\n",
    "    rec=npdet/(npos+0.00001)\n",
    "    #print(npos,npdet,rec)\n",
    "    return rec\n",
    "\n",
    "def eval1(da,dy,dist):\n",
    "    # dGt = dt of GT\n",
    "    # da =  dt of result\n",
    "    dr=da<=dist\n",
    "    prec=precision(da==0,dy<=dist)\n",
    "    rec=recall(dr,dy==0)    \n",
    "    return prec,rec\n",
    "\n",
    "def AHD(da,dy):\n",
    "    day=da[dy==0]\n",
    "    dya=dy[da==0]\n",
    "    return (np.mean(day)+np.mean(dya)).item()/2\n",
    "\n",
    "#m=load_images('d:/training/guidewire/resultMSL886/',test[:],'.png',0,'cpu')\n",
    "#plt.imshow(m,cmap='gray')\n",
    "todo=test\n",
    "nit=3\n",
    "npts=10\n",
    "dmax=np.arange(1,nit+1)*40\n",
    "#dmax=np.ones(nit)*40\n",
    "rho=0.7\n",
    "tau=10\n",
    "lmin=0\n",
    "poly=0\n",
    "print(nit,npts,dmax,rho,tau,poly,lmin)\n",
    "#log2file('eval_loc.txt','merge_curves nit=%d thr=%.1f'%(nit,thr))\n",
    "#for name in names:\n",
    "#path='d:/datasets/cathaction/'\n",
    "names=[]\n",
    "for i in range(4):\n",
    "    name='MSLLorNN_%d'%i\n",
    "    names.append(name)\n",
    "    pathl=path+'resultsLoc/'+name+'/'\n",
    "    os.makedirs(pathl, exist_ok=True)\n",
    "    path1=path+'resultsCv/'+name+'/'\n",
    "    os.makedirs(path1, exist_ok=True)\n",
    "print(names)\n",
    "n=len(test)\n",
    "nclf=len(names)\n",
    "allp=np.zeros((n,nclf))\n",
    "allr=np.zeros((n,nclf))\n",
    "alln=np.zeros((n,nclf))\n",
    "allt=np.zeros((n,nclf))\n",
    "ious=np.zeros((n,nclf))\n",
    "dices=np.zeros((n,nclf))\n",
    "ahds=np.zeros((n,nclf))\n",
    "valid=np.ones((n,nclf),dtype=np.int32)\n",
    "thr=0\n",
    "for i in range(n):\n",
    "    fname=test[i]\n",
    "    yi=load_mask1(path,fname)\n",
    "    yi=thin(yi>0)\n",
    "    dy=ndimage.distance_transform_edt(1-yi)\n",
    "    yi=torch.tensor(yi).float()\n",
    "    nr,nc=yi.shape\n",
    "    for j in range(nclf):\n",
    "        pathr=path+'Results/'+names[j]+'/'+fname+'.png'\n",
    "        #paths='d:/tmp/Results/'+test[i]+'.bmp'\n",
    "        pathl=path+'resultsLoc/'+names[j]+'/'\n",
    "        path1=path+'resultsCv/'+names[j]+'/'\n",
    "        if not os.path.exists(pathr):\n",
    "            print(pathr,'not found')\n",
    "            valid[i,j]=0\n",
    "            continue\n",
    "        im=load_image(pathr).squeeze()*255\n",
    "        if len(im.shape)>2:\n",
    "            im=im[0,:,:]\n",
    "        t=0\n",
    "        #fname=alls[k][i]\n",
    "        #cv=load_cvs(path+'/'+fname+'.mat')\n",
    "        #print(len(cv),cv[0].shape)\n",
    "        t0=time()\n",
    "        cv=extractCurves(im>0./255,8)\n",
    "        #print(len(cv),cv[0].shape)\n",
    "        #cv1\n",
    "        if 0:\n",
    "            pathr=path+'Images/'+fname+'.png'\n",
    "            im=load_image(pathr).squeeze()\n",
    "            if len(im.shape)>2:\n",
    "                im=im[0,:,:]\n",
    "        #print(im.shape)\n",
    "        cv0=cv\n",
    "        cv=merge_curves(cv,nit,npts,dmax,rho,tau,poly)\n",
    "        cv=removeshortcurves(cv,lmin)\n",
    "        allt[i,j]=time()-t0\n",
    "        xr=torch.zeros(dy.shape).t()\n",
    "        xr=draw_cvs(xr,cv).t()\n",
    "        xr=(xr>thr).float()\n",
    "        dx=ndimage.distance_transform_edt(1-xr)\n",
    "        pi,ri=eval1(dx,dy,3)\n",
    "        dices[i,j]=Dice(yi,xr)\n",
    "        ious[i,j]=iou1(yi,xr)\n",
    "        ahds[i,j]=AHD(dx,dy)\n",
    "        allp[i,j]=pi\n",
    "        allr[i,j]=ri\n",
    "        #break\n",
    "        #fi=2*pi*ri/(pi+ri)\n",
    "        alln[i,j]=len(cv)\n",
    "        name1=pathl+fname+'.png'\n",
    "        #save_result(name1,(xr>0).float()*255)\n",
    "        name1=path1+fname+'.png'\n",
    "        #save_plot(name1,cv,im,200)\n",
    "        name1=path1+fname+'.pth'\n",
    "        #torch.save(cv,name1)\n",
    "    if i%100==0:\n",
    "        p,r=np.mean(allp[:i+1,0]),np.mean(allr[:i+1,0])\n",
    "        d,io=np.mean(dices[:i+1,0]),np.mean(ious[:i+1,0])\n",
    "        f=2*p*r/(p+r)\n",
    "        print('%d %s %1.2f %1.2f %1.2f %1.2f %1.2f %.1f'%(i,fname,p*100,r*100,f*100,d*100,io*100, np.mean(alln[:i+1,0])))\n",
    "p,r,f,d,io,n,ah=[],[],[],[],[],[],[]\n",
    "for j in range(nclf):\n",
    "    p.append(np.mean(allp[valid[:,j]==1,j])*100)\n",
    "    r.append(np.mean(allr[valid[:,j]==1,j])*100)\n",
    "    d.append(np.mean(dices[valid[:,j]==1,j])*100)\n",
    "    io.append(np.mean(ious[valid[:,j]==1,j])*100) \n",
    "    ah.append(np.mean(np.mean(ahds[(valid[:,j]==1)&(np.isnan(ahds[:,j])==False),j]))) \n",
    "    n.append(np.mean(alln[valid[:,j]==1,j])) \n",
    "    f.append(2*p[j]*r[j]/(p[j]+r[j]))\n",
    "    log2file('eval_loc.txt','%s %.2f %1.2f %1.2f %1.2f %1.2f %1.2f %.1f %.1f'%(names[j],thr,p[j],r[j],f[j],d[j],io[j],ah[j],n[j]))\n",
    "if len(p)>1:\n",
    "    log2file('eval_loc.txt','nit=%d,pts=%d,dmax=%d,rho=%.1f,tau=%d,poly=%d,lmin=%d: \\n &%1.2f (%.2f) &%1.2f (%.2f) &%1.2f (%1.2f) &%1.2f (%1.2f) &%1.2f (%1.2f) &%1.1f (%1.1f) &%1.1f (%1.1f)'%(nit,npts,dmax[0],rho,tau,poly,lmin,\n",
    "        np.mean(p),np.std(p),np.mean(r),np.std(r),np.mean(f),np.std(f),np.mean(d),np.std(d),np.mean(io),np.std(io),np.mean(ah),np.std(ah),np.mean(n),np.std(n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
