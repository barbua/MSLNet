{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g5allA7N47RG",
    "outputId": "29c71e2e-65d7-4f85-9675-89f7c5c10082"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Fn\n",
    "from time import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.io.image import read_image\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, RandomCrop,ToTensor, Normalize, Grayscale, RandomRotation\n",
    "from torchvision.transforms.v2 import  RandomResize\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "from torchvision.io.image import read_image,write_png\n",
    "import torchvision.models as models\n",
    "from torchvision.models import resnet50, ResNet50_Weights,resnet101, ResNet101_Weights,resnet152, ResNet152_Weights\n",
    "import torchvision.transforms.functional as vF\n",
    "\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import inspect\n",
    "import multiprocessing\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import warnings\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "from time import time, sleep\n",
    "from typing import Tuple, Union, List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from batchgenerators.dataloading.multi_threaded_augmenter import MultiThreadedAugmenter\n",
    "from batchgenerators.dataloading.nondet_multi_threaded_augmenter import NonDetMultiThreadedAugmenter\n",
    "from batchgenerators.dataloading.single_threaded_augmenter import SingleThreadedAugmenter\n",
    "from batchgenerators.utilities.file_and_folder_operations import join, load_json, isfile, save_json, maybe_mkdir_p\n",
    "from batchgeneratorsv2.helpers.scalar_type import RandomScalar\n",
    "from batchgeneratorsv2.transforms.base.basic_transform import BasicTransform\n",
    "from batchgeneratorsv2.transforms.intensity.brightness import MultiplicativeBrightnessTransform\n",
    "from batchgeneratorsv2.transforms.intensity.contrast import ContrastTransform, BGContrast\n",
    "from batchgeneratorsv2.transforms.intensity.gamma import GammaTransform\n",
    "from batchgeneratorsv2.transforms.intensity.gaussian_noise import GaussianNoiseTransform\n",
    "from batchgeneratorsv2.transforms.nnunet.random_binary_operator import ApplyRandomBinaryOperatorTransform\n",
    "from batchgeneratorsv2.transforms.nnunet.remove_connected_components import \\\n",
    "    RemoveRandomConnectedComponentFromOneHotEncodingTransform\n",
    "from batchgeneratorsv2.transforms.nnunet.seg_to_onehot import MoveSegAsOneHotToDataTransform\n",
    "from batchgeneratorsv2.transforms.noise.gaussian_blur import GaussianBlurTransform\n",
    "from batchgeneratorsv2.transforms.spatial.low_resolution import SimulateLowResolutionTransform\n",
    "from batchgeneratorsv2.transforms.spatial.mirroring import MirrorTransform\n",
    "from batchgeneratorsv2.transforms.spatial.spatial import SpatialTransform\n",
    "from batchgeneratorsv2.transforms.utils.compose import ComposeTransforms\n",
    "from batchgeneratorsv2.transforms.utils.deep_supervision_downsampling import DownsampleSegForDSTransform\n",
    "from batchgeneratorsv2.transforms.utils.nnunet_masking import MaskImageTransform\n",
    "from batchgeneratorsv2.transforms.utils.random import RandomTransform\n",
    "from batchgeneratorsv2.transforms.utils.remove_label import RemoveLabelTansform\n",
    "from batchgeneratorsv2.transforms.utils.seg_to_regions import ConvertSegmentationToRegionsTransform\n",
    "from torch import autocast, nn\n",
    "from torch import distributed as dist\n",
    "from torch._dynamo import OptimizedModule\n",
    "from torch.cuda import device_count\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from MSLNet import MSLNet,get_y0,get_patches,get_allpatches,set_nov_patches,set_nov_patches2\n",
    "\n",
    "try:\n",
    "    from torchvision.transforms import InterpolationMode\n",
    "    BICUBIC = InterpolationMode.BICUBIC\n",
    "except ImportError:\n",
    "    BICUBIC = Image.BICUBIC # resize the input image using bicubic interpolation, producing a smoother result compared to other interpolation methods like device = torch.device(\"cuda\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "['0']\n",
      "<enumerate object at 0x0000024ECF898950>\n",
      "D:\\Datasets\\nnUNet_results\\Dataset316_CathAction\\nnUNetTrainer__nnUNetPlans__2d\\MSLNet_0\\checkpoint_final.pth\n",
      "There are 4691 cases in the source folder\n",
      "I am process 0 out of 1 (max process ID is 0, we start counting with 0!)\n",
      "There are 4691 cases that I would like to predict\n",
      "\n",
      "Predicting ani_00004:\n",
      "perform_everything_on_device: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 512, 273]) tensor([   0, 2523], device='cuda:0')\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with ani_00004\n",
      "\n",
      "Predicting ani_00007:\n",
      "perform_everything_on_device: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 512, 512]) tensor([   0, 2142], device='cuda:0')\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with ani_00007\n",
      "\n",
      "Predicting ani_00015:\n",
      "perform_everything_on_device: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 512, 512]) tensor([   0, 2805], device='cuda:0')\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with ani_00015\n",
      "\n",
      "Predicting ani_00019:\n",
      "perform_everything_on_device: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 512, 426]) tensor([   0, 1631], device='cuda:0')\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with ani_00019\n",
      "\n",
      "Predicting ani_00038:\n",
      "perform_everything_on_device: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 512, 512]) tensor([   0, 2136], device='cuda:0')\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with ani_00038\n",
      "\n",
      "Predicting ani_00042:\n",
      "perform_everything_on_device: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 512, 512]) tensor([   0, 2657], device='cuda:0')\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with ani_00042\n",
      "\n",
      "Predicting ani_00044:\n",
      "perform_everything_on_device: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 512, 512]) tensor([   0, 2876], device='cuda:0')\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with ani_00044\n",
      "\n",
      "Predicting ani_00055:\n",
      "perform_everything_on_device: True\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 890\u001b[0m\n\u001b[0;32m    877\u001b[0m predictor \u001b[38;5;241m=\u001b[39m nnUNetPredictor(tile_step_size\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mstep_size,\n\u001b[0;32m    878\u001b[0m                             use_gaussian\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    879\u001b[0m                             use_mirroring\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m args\u001b[38;5;241m.\u001b[39mdisable_tta,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    883\u001b[0m                             verbose_preprocessing\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    884\u001b[0m                             allow_tqdm\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m args\u001b[38;5;241m.\u001b[39mdisable_progress_bar)\n\u001b[0;32m    885\u001b[0m predictor\u001b[38;5;241m.\u001b[39minitialize_from_trained_model_folder(\n\u001b[0;32m    886\u001b[0m     model_folder,\n\u001b[0;32m    887\u001b[0m     args\u001b[38;5;241m.\u001b[39mf,\n\u001b[0;32m    888\u001b[0m     checkpoint_name\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mchk\n\u001b[0;32m    889\u001b[0m )\n\u001b[1;32m--> 890\u001b[0m a\u001b[38;5;241m=\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_from_files(args\u001b[38;5;241m.\u001b[39mi, args\u001b[38;5;241m.\u001b[39mo, save_probabilities\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39msave_probabilities,\n\u001b[0;32m    891\u001b[0m                              overwrite\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m args\u001b[38;5;241m.\u001b[39mcontinue_prediction,\n\u001b[0;32m    892\u001b[0m                              num_processes_preprocessing\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mnpp,\n\u001b[0;32m    893\u001b[0m                              num_processes_segmentation_export\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mnps,\n\u001b[0;32m    894\u001b[0m                              folder_with_segs_from_prev_stage\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mprev_stage_predictions,\n\u001b[0;32m    895\u001b[0m                              num_parts\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mnum_parts,\n\u001b[0;32m    896\u001b[0m                              part_id\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mpart_id)\n",
      "Cell \u001b[1;32mIn[2], line 278\u001b[0m, in \u001b[0;36mnnUNetPredictor.predict_from_files\u001b[1;34m(self, list_of_lists_or_source_folder, output_folder_or_list_of_truncated_output_files, save_probabilities, overwrite, num_processes_preprocessing, num_processes_segmentation_export, folder_with_segs_from_prev_stage, num_parts, part_id)\u001b[0m\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    273\u001b[0m data_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_get_data_iterator_from_lists_of_filenames(list_of_lists_or_source_folder,\n\u001b[0;32m    274\u001b[0m                                                                          seg_from_prev_stage_files,\n\u001b[0;32m    275\u001b[0m                                                                          output_filename_truncated,\n\u001b[0;32m    276\u001b[0m                                                                          num_processes_preprocessing)\n\u001b[1;32m--> 278\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_from_data_iterator(data_iterator, save_probabilities, num_processes_segmentation_export)\n",
      "Cell \u001b[1;32mIn[2], line 395\u001b[0m, in \u001b[0;36mnnUNetPredictor.predict_from_data_iterator\u001b[1;34m(self, data_iterator, save_probabilities, num_processes_segmentation_export)\u001b[0m\n\u001b[0;32m    392\u001b[0m     sleep(\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m    393\u001b[0m     proceed \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m check_workers_alive_and_busy(export_pool, worker_list, r, allowed_num_queued\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 395\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_logits_from_preprocessed_data(data)\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ofile \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    398\u001b[0m     \u001b[38;5;66;03m# this needs to go into background processes\u001b[39;00m\n\u001b[0;32m    399\u001b[0m     \u001b[38;5;66;03m# export_prediction_from_logits(prediction, properties, self.configuration_manager, self.plans_manager,\u001b[39;00m\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;66;03m#                               self.dataset_json, ofile, save_probabilities)\u001b[39;00m\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msending off prediction to background worker for resampling and export\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 504\u001b[0m, in \u001b[0;36mnnUNetPredictor.predict_logits_from_preprocessed_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m params \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlist_of_parameters:\n\u001b[0;32m    501\u001b[0m \n\u001b[0;32m    502\u001b[0m     \u001b[38;5;66;03m# messing with state dict names...\u001b[39;00m\n\u001b[0;32m    503\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork, OptimizedModule):\n\u001b[1;32m--> 504\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39mload_state_dict(params)\n\u001b[0;32m    505\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39m_orig_mod\u001b[38;5;241m.\u001b[39mload_state_dict(params)\n",
      "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2604\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2597\u001b[0m         out \u001b[38;5;241m=\u001b[39m hook(module, incompatible_keys)\n\u001b[0;32m   2598\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, (\n\u001b[0;32m   2599\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHooks registered with ``register_load_state_dict_post_hook`` are not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2600\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected to return new values, if incompatible_keys need to be modified,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2601\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mit should be done inplace.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2602\u001b[0m         )\n\u001b[1;32m-> 2604\u001b[0m load(\u001b[38;5;28mself\u001b[39m, state_dict)\n\u001b[0;32m   2605\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m load\n\u001b[0;32m   2607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strict:\n",
      "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2592\u001b[0m, in \u001b[0;36mModule.load_state_dict.<locals>.load\u001b[1;34m(module, local_state_dict, prefix)\u001b[0m\n\u001b[0;32m   2586\u001b[0m         child_prefix \u001b[38;5;241m=\u001b[39m prefix \u001b[38;5;241m+\u001b[39m name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2587\u001b[0m         child_state_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   2588\u001b[0m             k: v\n\u001b[0;32m   2589\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m local_state_dict\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   2590\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m k\u001b[38;5;241m.\u001b[39mstartswith(child_prefix)\n\u001b[0;32m   2591\u001b[0m         }\n\u001b[1;32m-> 2592\u001b[0m         load(child, child_state_dict, child_prefix)  \u001b[38;5;66;03m# noqa: F821\u001b[39;00m\n\u001b[0;32m   2594\u001b[0m \u001b[38;5;66;03m# Note that the hook can modify missing_keys and unexpected_keys.\u001b[39;00m\n\u001b[0;32m   2595\u001b[0m incompatible_keys \u001b[38;5;241m=\u001b[39m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2592\u001b[0m, in \u001b[0;36mModule.load_state_dict.<locals>.load\u001b[1;34m(module, local_state_dict, prefix)\u001b[0m\n\u001b[0;32m   2586\u001b[0m         child_prefix \u001b[38;5;241m=\u001b[39m prefix \u001b[38;5;241m+\u001b[39m name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2587\u001b[0m         child_state_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   2588\u001b[0m             k: v\n\u001b[0;32m   2589\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m local_state_dict\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   2590\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m k\u001b[38;5;241m.\u001b[39mstartswith(child_prefix)\n\u001b[0;32m   2591\u001b[0m         }\n\u001b[1;32m-> 2592\u001b[0m         load(child, child_state_dict, child_prefix)  \u001b[38;5;66;03m# noqa: F821\u001b[39;00m\n\u001b[0;32m   2594\u001b[0m \u001b[38;5;66;03m# Note that the hook can modify missing_keys and unexpected_keys.\u001b[39;00m\n\u001b[0;32m   2595\u001b[0m incompatible_keys \u001b[38;5;241m=\u001b[39m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "    \u001b[1;31m[... skipping similar frames: Module.load_state_dict.<locals>.load at line 2592 (1 times)]\u001b[0m\n",
      "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2592\u001b[0m, in \u001b[0;36mModule.load_state_dict.<locals>.load\u001b[1;34m(module, local_state_dict, prefix)\u001b[0m\n\u001b[0;32m   2586\u001b[0m         child_prefix \u001b[38;5;241m=\u001b[39m prefix \u001b[38;5;241m+\u001b[39m name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2587\u001b[0m         child_state_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   2588\u001b[0m             k: v\n\u001b[0;32m   2589\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m local_state_dict\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   2590\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m k\u001b[38;5;241m.\u001b[39mstartswith(child_prefix)\n\u001b[0;32m   2591\u001b[0m         }\n\u001b[1;32m-> 2592\u001b[0m         load(child, child_state_dict, child_prefix)  \u001b[38;5;66;03m# noqa: F821\u001b[39;00m\n\u001b[0;32m   2594\u001b[0m \u001b[38;5;66;03m# Note that the hook can modify missing_keys and unexpected_keys.\u001b[39;00m\n\u001b[0;32m   2595\u001b[0m incompatible_keys \u001b[38;5;241m=\u001b[39m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2575\u001b[0m, in \u001b[0;36mModule.load_state_dict.<locals>.load\u001b[1;34m(module, local_state_dict, prefix)\u001b[0m\n\u001b[0;32m   2573\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m assign:\n\u001b[0;32m   2574\u001b[0m     local_metadata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massign_to_params_buffers\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m assign\n\u001b[1;32m-> 2575\u001b[0m module\u001b[38;5;241m.\u001b[39m_load_from_state_dict(\n\u001b[0;32m   2576\u001b[0m     local_state_dict,\n\u001b[0;32m   2577\u001b[0m     prefix,\n\u001b[0;32m   2578\u001b[0m     local_metadata,\n\u001b[0;32m   2579\u001b[0m     \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   2580\u001b[0m     missing_keys,\n\u001b[0;32m   2581\u001b[0m     unexpected_keys,\n\u001b[0;32m   2582\u001b[0m     error_msgs,\n\u001b[0;32m   2583\u001b[0m )\n\u001b[0;32m   2584\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   2585\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:132\u001b[0m, in \u001b[0;36m_NormBase._load_from_state_dict\u001b[1;34m(self, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num_batches_tracked_key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m state_dict:\n\u001b[0;32m    125\u001b[0m         state_dict[num_batches_tracked_key] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    126\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches_tracked\n\u001b[0;32m    127\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches_tracked \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    128\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches_tracked\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    129\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[0;32m    130\u001b[0m         )\n\u001b[1;32m--> 132\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_load_from_state_dict(\n\u001b[0;32m    133\u001b[0m     state_dict,\n\u001b[0;32m    134\u001b[0m     prefix,\n\u001b[0;32m    135\u001b[0m     local_metadata,\n\u001b[0;32m    136\u001b[0m     strict,\n\u001b[0;32m    137\u001b[0m     missing_keys,\n\u001b[0;32m    138\u001b[0m     unexpected_keys,\n\u001b[0;32m    139\u001b[0m     error_msgs,\n\u001b[0;32m    140\u001b[0m )\n",
      "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2482\u001b[0m, in \u001b[0;36mModule._load_from_state_dict\u001b[1;34m(self, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)\u001b[0m\n\u001b[0;32m   2480\u001b[0m             \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, input_param)\n\u001b[0;32m   2481\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2482\u001b[0m             param\u001b[38;5;241m.\u001b[39mcopy_(input_param)\n\u001b[0;32m   2483\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m   2484\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mswapping\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_swap_tensors \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcopying\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "import itertools\n",
    "import multiprocessing\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from time import sleep\n",
    "from typing import Tuple, Union, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from acvl_utils.cropping_and_padding.padding import pad_nd_image\n",
    "from batchgenerators.dataloading.multi_threaded_augmenter import MultiThreadedAugmenter\n",
    "from batchgenerators.utilities.file_and_folder_operations import load_json, join, isfile, maybe_mkdir_p, isdir, subdirs, \\\n",
    "    save_json\n",
    "from torch import nn\n",
    "from torch._dynamo import OptimizedModule\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nnunetv2\n",
    "from nnunetv2.configuration import default_num_processes\n",
    "from nnunetv2.inference.data_iterators import PreprocessAdapterFromNpy, preprocessing_iterator_fromfiles, \\\n",
    "    preprocessing_iterator_fromnpy\n",
    "from nnunetv2.inference.export_prediction import export_prediction_from_logits, \\\n",
    "    convert_predicted_logits_to_segmentation_with_correct_shape\n",
    "from nnunetv2.inference.sliding_window_prediction import compute_gaussian, \\\n",
    "    compute_steps_for_sliding_window\n",
    "from nnunetv2.utilities.file_path_utilities import get_output_folder, check_workers_alive_and_busy\n",
    "from nnunetv2.utilities.find_class_by_name import recursive_find_python_class\n",
    "from nnunetv2.utilities.helpers import empty_cache, dummy_context\n",
    "from nnunetv2.utilities.json_export import recursive_fix_for_json_export\n",
    "from nnunetv2.utilities.label_handling.label_handling import determine_num_input_channels\n",
    "from nnunetv2.utilities.plans_handling.plans_handler import PlansManager, ConfigurationManager\n",
    "from nnunetv2.utilities.utils import create_lists_from_splitted_dataset_folder\n",
    "\n",
    "\n",
    "class nnUNetPredictor(object):\n",
    "    def __init__(self,\n",
    "                 tile_step_size: float = 0.5,\n",
    "                 use_gaussian: bool = True,\n",
    "                 use_mirroring: bool = True,\n",
    "                 perform_everything_on_device: bool = True,\n",
    "                 device: torch.device = torch.device('cuda'),\n",
    "                 verbose: bool = False,\n",
    "                 verbose_preprocessing: bool = False,\n",
    "                 allow_tqdm: bool = True):\n",
    "        self.verbose = verbose\n",
    "        self.verbose_preprocessing = verbose_preprocessing\n",
    "        self.allow_tqdm = allow_tqdm\n",
    "\n",
    "        self.plans_manager, self.configuration_manager, self.list_of_parameters, self.network, self.dataset_json, \\\n",
    "        self.trainer_name, self.allowed_mirroring_axes, self.label_manager = None, None, None, None, None, None, None, None\n",
    "\n",
    "        self.tile_step_size = tile_step_size\n",
    "        self.use_gaussian = use_gaussian\n",
    "        self.use_mirroring = use_mirroring\n",
    "        if device.type == 'cuda':\n",
    "            torch.backends.cudnn.benchmark = True\n",
    "        else:\n",
    "            print(f'perform_everything_on_device=True is only supported for cuda devices! Setting this to False')\n",
    "            perform_everything_on_device = False\n",
    "        self.device = device\n",
    "        self.perform_everything_on_device = perform_everything_on_device\n",
    "\n",
    "    def initialize_from_trained_model_folder(self, model_training_output_dir: str,\n",
    "                                             use_folds: Union[Tuple[Union[int, str]], None],\n",
    "                                             checkpoint_name: str = 'checkpoint_final.pth'):\n",
    "        \"\"\"\n",
    "        This is used when making predictions with a trained model\n",
    "        \"\"\"\n",
    "        if use_folds is None:\n",
    "            use_folds = nnUNetPredictor.auto_detect_available_folds(model_training_output_dir, checkpoint_name)\n",
    "\n",
    "        dataset_json = load_json(join(model_training_output_dir, 'dataset.json'))\n",
    "        plans = load_json(join(model_training_output_dir, 'plans.json'))\n",
    "        plans_manager = PlansManager(plans)\n",
    "\n",
    "        if isinstance(use_folds, str):\n",
    "            use_folds = [use_folds]\n",
    "        print(use_folds)\n",
    "        print(enumerate(use_folds))\n",
    "        parameters = []\n",
    "        for i, f in enumerate(use_folds):\n",
    "            f = int(f) if f != 'all' else f\n",
    "            name=join(model_training_output_dir, f'MSLNet_{f}', checkpoint_name)\n",
    "            print(name)\n",
    "            checkpoint = torch.load(name,map_location=torch.device('cpu'),weights_only=False)\n",
    "            if i == 0:\n",
    "                trainer_name = checkpoint['trainer_name']\n",
    "                configuration_name = checkpoint['init_args']['configuration']\n",
    "                inference_allowed_mirroring_axes = checkpoint['inference_allowed_mirroring_axes'] if \\\n",
    "                    'inference_allowed_mirroring_axes' in checkpoint.keys() else None\n",
    "\n",
    "            parameters.append(checkpoint['network_weights'])\n",
    "\n",
    "        configuration_manager = plans_manager.get_configuration(configuration_name)\n",
    "        # restore network\n",
    "        num_input_channels = determine_num_input_channels(plans_manager, configuration_manager, dataset_json)\n",
    "        trainer_class = recursive_find_python_class(join(nnunetv2.__path__[0], \"training\", \"nnUNetTrainer\"),\n",
    "                                                    trainer_name, 'nnunetv2.training.nnUNetTrainer')\n",
    "        if trainer_class is None:\n",
    "            raise RuntimeError(f'Unable to locate trainer class {trainer_name} in nnunetv2.training.nnUNetTrainer. '\n",
    "                               f'Please place it there (in any .py file)!')\n",
    "        if 0:\n",
    "            network = trainer_class.build_network_architecture(\n",
    "                configuration_manager.network_arch_class_name,\n",
    "                configuration_manager.network_arch_init_kwargs,\n",
    "                configuration_manager.network_arch_init_kwargs_req_import,\n",
    "                num_input_channels,\n",
    "                plans_manager.get_label_manager(dataset_json).num_segmentation_heads,\n",
    "                enable_deep_supervision=False\n",
    "            )\n",
    "        else:\n",
    "            network=MSLNet(device)\n",
    "\n",
    "        self.plans_manager = plans_manager\n",
    "        self.configuration_manager = configuration_manager\n",
    "        self.list_of_parameters = parameters\n",
    "        self.network = network\n",
    "        self.dataset_json = dataset_json\n",
    "        self.trainer_name = trainer_name\n",
    "        self.allowed_mirroring_axes = inference_allowed_mirroring_axes\n",
    "        self.label_manager = plans_manager.get_label_manager(dataset_json)\n",
    "        if ('nnUNet_compile' in os.environ.keys()) and (os.environ['nnUNet_compile'].lower() in ('true', '1', 't')) \\\n",
    "                and not isinstance(self.network, OptimizedModule):\n",
    "            print('Using torch.compile')\n",
    "            self.network = torch.compile(self.network)\n",
    "\n",
    "    def network1(self,x):\n",
    "        #prediction = self.network(x)\n",
    "        py0,prediction = self.network(x)\n",
    "        prediction=prediction.permute(0,2,3,1) #nx32x32x256\n",
    "        xr=set_nov_patches2(prediction,16)\n",
    "        if 1:\n",
    "            xr1=xr[:,1,:,:]\n",
    "            #print(py0.shape,prediction.shape,xr.shape)\n",
    "            py0=torch.argmax(py0,dim=1)\n",
    "            ni,nr,nc=py0.shape\n",
    "            py1=vF.resize(py0,(nr*16,nc*16),interpolation=InterpolationMode.NEAREST_EXACT)\n",
    "            xr1[py1<=0]=-1\n",
    "            xr[:,1,:,:]=xr1\n",
    "        return xr\n",
    "\n",
    "    def manual_initialization(self, network: nn.Module, plans_manager: PlansManager,\n",
    "                              configuration_manager: ConfigurationManager, parameters: Optional[List[dict]],\n",
    "                              dataset_json: dict, trainer_name: str,\n",
    "                              inference_allowed_mirroring_axes: Optional[Tuple[int, ...]]):\n",
    "        \"\"\"\n",
    "        This is used by the nnUNetTrainer to initialize nnUNetPredictor for the final validation\n",
    "        \"\"\"\n",
    "        self.plans_manager = plans_manager\n",
    "        self.configuration_manager = configuration_manager\n",
    "        self.list_of_parameters = parameters\n",
    "        self.network = network\n",
    "        self.dataset_json = dataset_json\n",
    "        self.trainer_name = trainer_name\n",
    "        self.allowed_mirroring_axes = inference_allowed_mirroring_axes\n",
    "        self.label_manager = plans_manager.get_label_manager(dataset_json)\n",
    "        allow_compile = True\n",
    "        allow_compile = allow_compile and ('nnUNet_compile' in os.environ.keys()) and (\n",
    "                    os.environ['nnUNet_compile'].lower() in ('true', '1', 't'))\n",
    "        allow_compile = allow_compile and not isinstance(self.network, OptimizedModule)\n",
    "        if isinstance(self.network, DistributedDataParallel):\n",
    "            allow_compile = allow_compile and isinstance(self.network.module, OptimizedModule)\n",
    "        if allow_compile:\n",
    "            print('Using torch.compile')\n",
    "            self.network = torch.compile(self.network)\n",
    "\n",
    "    @staticmethod\n",
    "    def auto_detect_available_folds(model_training_output_dir, checkpoint_name):\n",
    "        print('use_folds is None, attempting to auto detect available folds')\n",
    "        fold_folders = subdirs(model_training_output_dir, prefix='fold_', join=False)\n",
    "        fold_folders = [i for i in fold_folders if i != 'fold_all']\n",
    "        fold_folders = [i for i in fold_folders if isfile(join(model_training_output_dir, i, checkpoint_name))]\n",
    "        use_folds = [int(i.split('_')[-1]) for i in fold_folders]\n",
    "        print(f'found the following folds: {use_folds}')\n",
    "        return use_folds\n",
    "\n",
    "    def _manage_input_and_output_lists(self, list_of_lists_or_source_folder: Union[str, List[List[str]]],\n",
    "                                       output_folder_or_list_of_truncated_output_files: Union[None, str, List[str]],\n",
    "                                       folder_with_segs_from_prev_stage: str = None,\n",
    "                                       overwrite: bool = True,\n",
    "                                       part_id: int = 0,\n",
    "                                       num_parts: int = 1,\n",
    "                                       save_probabilities: bool = False):\n",
    "        if isinstance(list_of_lists_or_source_folder, str):\n",
    "            list_of_lists_or_source_folder = create_lists_from_splitted_dataset_folder(list_of_lists_or_source_folder,\n",
    "                                                                                       self.dataset_json['file_ending'])\n",
    "        print(f'There are {len(list_of_lists_or_source_folder)} cases in the source folder')\n",
    "        list_of_lists_or_source_folder = list_of_lists_or_source_folder[part_id::num_parts]\n",
    "        caseids = [os.path.basename(i[0])[:-(len(self.dataset_json['file_ending']) + 5)] for i in\n",
    "                   list_of_lists_or_source_folder]\n",
    "        print(\n",
    "            f'I am process {part_id} out of {num_parts} (max process ID is {num_parts - 1}, we start counting with 0!)')\n",
    "        print(f'There are {len(caseids)} cases that I would like to predict')\n",
    "\n",
    "        if isinstance(output_folder_or_list_of_truncated_output_files, str):\n",
    "            output_filename_truncated = [join(output_folder_or_list_of_truncated_output_files, i) for i in caseids]\n",
    "        else:\n",
    "            output_filename_truncated = output_folder_or_list_of_truncated_output_files\n",
    "\n",
    "        seg_from_prev_stage_files = [join(folder_with_segs_from_prev_stage, i + self.dataset_json['file_ending']) if\n",
    "                                     folder_with_segs_from_prev_stage is not None else None for i in caseids]\n",
    "        # remove already predicted files form the lists\n",
    "        if not overwrite and output_filename_truncated is not None:\n",
    "            tmp = [isfile(i + self.dataset_json['file_ending']) for i in output_filename_truncated]\n",
    "            if save_probabilities:\n",
    "                tmp2 = [isfile(i + '.npz') for i in output_filename_truncated]\n",
    "                tmp = [i and j for i, j in zip(tmp, tmp2)]\n",
    "            not_existing_indices = [i for i, j in enumerate(tmp) if not j]\n",
    "\n",
    "            output_filename_truncated = [output_filename_truncated[i] for i in not_existing_indices]\n",
    "            list_of_lists_or_source_folder = [list_of_lists_or_source_folder[i] for i in not_existing_indices]\n",
    "            seg_from_prev_stage_files = [seg_from_prev_stage_files[i] for i in not_existing_indices]\n",
    "            print(f'overwrite was set to {overwrite}, so I am only working on cases that haven\\'t been predicted yet. '\n",
    "                  f'That\\'s {len(not_existing_indices)} cases.')\n",
    "        return list_of_lists_or_source_folder, output_filename_truncated, seg_from_prev_stage_files\n",
    "\n",
    "    def predict_from_files(self,\n",
    "                           list_of_lists_or_source_folder: Union[str, List[List[str]]],\n",
    "                           output_folder_or_list_of_truncated_output_files: Union[str, None, List[str]],\n",
    "                           save_probabilities: bool = False,\n",
    "                           overwrite: bool = True,\n",
    "                           num_processes_preprocessing: int = default_num_processes,\n",
    "                           num_processes_segmentation_export: int = default_num_processes,\n",
    "                           folder_with_segs_from_prev_stage: str = None,\n",
    "                           num_parts: int = 1,\n",
    "                           part_id: int = 0):\n",
    "        \"\"\"\n",
    "        This is nnU-Net's default function for making predictions. It works best for batch predictions\n",
    "        (predicting many images at once).\n",
    "        \"\"\"\n",
    "        if isinstance(output_folder_or_list_of_truncated_output_files, str):\n",
    "            output_folder = output_folder_or_list_of_truncated_output_files\n",
    "        elif isinstance(output_folder_or_list_of_truncated_output_files, list):\n",
    "            output_folder = os.path.dirname(output_folder_or_list_of_truncated_output_files[0])\n",
    "        else:\n",
    "            output_folder = None\n",
    "\n",
    "        ########################\n",
    "        # let's store the input arguments so that its clear what was used to generate the prediction\n",
    "        if output_folder is not None:\n",
    "            my_init_kwargs = {}\n",
    "            for k in inspect.signature(self.predict_from_files).parameters.keys():\n",
    "                my_init_kwargs[k] = locals()[k]\n",
    "            my_init_kwargs = deepcopy(\n",
    "                my_init_kwargs)  # let's not unintentionally change anything in-place. Take this as a\n",
    "            recursive_fix_for_json_export(my_init_kwargs)\n",
    "            maybe_mkdir_p(output_folder)\n",
    "            save_json(my_init_kwargs, join(output_folder, 'predict_from_raw_data_args.json'))\n",
    "\n",
    "            # we need these two if we want to do things with the predictions like for example apply postprocessing\n",
    "            save_json(self.dataset_json, join(output_folder, 'dataset.json'), sort_keys=False)\n",
    "            save_json(self.plans_manager.plans, join(output_folder, 'plans.json'), sort_keys=False)\n",
    "        #######################\n",
    "\n",
    "        # check if we need a prediction from the previous stage\n",
    "        if self.configuration_manager.previous_stage_name is not None:\n",
    "            assert folder_with_segs_from_prev_stage is not None, \\\n",
    "                f'The requested configuration is a cascaded network. It requires the segmentations of the previous ' \\\n",
    "                f'stage ({self.configuration_manager.previous_stage_name}) as input. Please provide the folder where' \\\n",
    "                f' they are located via folder_with_segs_from_prev_stage'\n",
    "\n",
    "        # sort out input and output filenames\n",
    "        list_of_lists_or_source_folder, output_filename_truncated, seg_from_prev_stage_files = \\\n",
    "            self._manage_input_and_output_lists(list_of_lists_or_source_folder,\n",
    "                                                output_folder_or_list_of_truncated_output_files,\n",
    "                                                folder_with_segs_from_prev_stage, overwrite, part_id, num_parts,\n",
    "                                                save_probabilities)\n",
    "        if len(list_of_lists_or_source_folder) == 0:\n",
    "            return\n",
    "\n",
    "        data_iterator = self._internal_get_data_iterator_from_lists_of_filenames(list_of_lists_or_source_folder,\n",
    "                                                                                 seg_from_prev_stage_files,\n",
    "                                                                                 output_filename_truncated,\n",
    "                                                                                 num_processes_preprocessing)\n",
    "\n",
    "        return self.predict_from_data_iterator(data_iterator, save_probabilities, num_processes_segmentation_export)\n",
    "\n",
    "    def _internal_get_data_iterator_from_lists_of_filenames(self,\n",
    "                                                            input_list_of_lists: List[List[str]],\n",
    "                                                            seg_from_prev_stage_files: Union[List[str], None],\n",
    "                                                            output_filenames_truncated: Union[List[str], None],\n",
    "                                                            num_processes: int):\n",
    "        return preprocessing_iterator_fromfiles(input_list_of_lists, seg_from_prev_stage_files,\n",
    "                                                output_filenames_truncated, self.plans_manager, self.dataset_json,\n",
    "                                                self.configuration_manager, num_processes, self.device.type == 'cuda',\n",
    "                                                self.verbose_preprocessing)\n",
    "        # preprocessor = self.configuration_manager.preprocessor_class(verbose=self.verbose_preprocessing)\n",
    "        # # hijack batchgenerators, yo\n",
    "        # # we use the multiprocessing of the batchgenerators dataloader to handle all the background worker stuff. This\n",
    "        # # way we don't have to reinvent the wheel here.\n",
    "        # num_processes = max(1, min(num_processes, len(input_list_of_lists)))\n",
    "        # ppa = PreprocessAdapter(input_list_of_lists, seg_from_prev_stage_files, preprocessor,\n",
    "        #                         output_filenames_truncated, self.plans_manager, self.dataset_json,\n",
    "        #                         self.configuration_manager, num_processes)\n",
    "        # if num_processes == 0:\n",
    "        #     mta = SingleThreadedAugmenter(ppa, None)\n",
    "        # else:\n",
    "        #     mta = MultiThreadedAugmenter(ppa, None, num_processes, 1, None, pin_memory=pin_memory)\n",
    "        # return mta\n",
    "\n",
    "    def get_data_iterator_from_raw_npy_data(self,\n",
    "                                            image_or_list_of_images: Union[np.ndarray, List[np.ndarray]],\n",
    "                                            segs_from_prev_stage_or_list_of_segs_from_prev_stage: Union[None,\n",
    "                                                                                                        np.ndarray,\n",
    "                                                                                                        List[\n",
    "                                                                                                            np.ndarray]],\n",
    "                                            properties_or_list_of_properties: Union[dict, List[dict]],\n",
    "                                            truncated_ofname: Union[str, List[str], None],\n",
    "                                            num_processes: int = 3):\n",
    "\n",
    "        list_of_images = [image_or_list_of_images] if not isinstance(image_or_list_of_images, list) else \\\n",
    "            image_or_list_of_images\n",
    "\n",
    "        if isinstance(segs_from_prev_stage_or_list_of_segs_from_prev_stage, np.ndarray):\n",
    "            segs_from_prev_stage_or_list_of_segs_from_prev_stage = [\n",
    "                segs_from_prev_stage_or_list_of_segs_from_prev_stage]\n",
    "\n",
    "        if isinstance(truncated_ofname, str):\n",
    "            truncated_ofname = [truncated_ofname]\n",
    "\n",
    "        if isinstance(properties_or_list_of_properties, dict):\n",
    "            properties_or_list_of_properties = [properties_or_list_of_properties]\n",
    "\n",
    "        num_processes = min(num_processes, len(list_of_images))\n",
    "        pp = preprocessing_iterator_fromnpy(\n",
    "            list_of_images,\n",
    "            segs_from_prev_stage_or_list_of_segs_from_prev_stage,\n",
    "            properties_or_list_of_properties,\n",
    "            truncated_ofname,\n",
    "            self.plans_manager,\n",
    "            self.dataset_json,\n",
    "            self.configuration_manager,\n",
    "            num_processes,\n",
    "            self.device.type == 'cuda',\n",
    "            self.verbose_preprocessing\n",
    "        )\n",
    "\n",
    "        return pp\n",
    "\n",
    "    def predict_from_list_of_npy_arrays(self,\n",
    "                                        image_or_list_of_images: Union[np.ndarray, List[np.ndarray]],\n",
    "                                        segs_from_prev_stage_or_list_of_segs_from_prev_stage: Union[None,\n",
    "                                                                                                    np.ndarray,\n",
    "                                                                                                    List[\n",
    "                                                                                                        np.ndarray]],\n",
    "                                        properties_or_list_of_properties: Union[dict, List[dict]],\n",
    "                                        truncated_ofname: Union[str, List[str], None],\n",
    "                                        num_processes: int = 3,\n",
    "                                        save_probabilities: bool = False,\n",
    "                                        num_processes_segmentation_export: int = default_num_processes):\n",
    "        iterator = self.get_data_iterator_from_raw_npy_data(image_or_list_of_images,\n",
    "                                                            segs_from_prev_stage_or_list_of_segs_from_prev_stage,\n",
    "                                                            properties_or_list_of_properties,\n",
    "                                                            truncated_ofname,\n",
    "                                                            num_processes)\n",
    "        return self.predict_from_data_iterator(iterator, save_probabilities, num_processes_segmentation_export)\n",
    "\n",
    "    def predict_from_data_iterator(self,\n",
    "                                   data_iterator,\n",
    "                                   save_probabilities: bool = False,\n",
    "                                   num_processes_segmentation_export: int = default_num_processes):\n",
    "        \"\"\"\n",
    "        each element returned by data_iterator must be a dict with 'data', 'ofile' and 'data_properties' keys!\n",
    "        If 'ofile' is None, the result will be returned instead of written to a file\n",
    "        \"\"\"\n",
    "        with multiprocessing.get_context(\"spawn\").Pool(num_processes_segmentation_export) as export_pool:\n",
    "            worker_list = [i for i in export_pool._pool]\n",
    "            r = []\n",
    "            for preprocessed in data_iterator:\n",
    "                data = preprocessed['data']\n",
    "                if isinstance(data, str):\n",
    "                    delfile = data\n",
    "                    data = torch.from_numpy(np.load(data))\n",
    "                    os.remove(delfile)\n",
    "\n",
    "                ofile = preprocessed['ofile']\n",
    "                if ofile is not None:\n",
    "                    print(f'\\nPredicting {os.path.basename(ofile)}:')\n",
    "                else:\n",
    "                    print(f'\\nPredicting image of shape {data.shape}:')\n",
    "\n",
    "                print(f'perform_everything_on_device: {self.perform_everything_on_device}')\n",
    "\n",
    "                properties = preprocessed['data_properties']\n",
    "\n",
    "                # let's not get into a runaway situation where the GPU predicts so fast that the disk has to b swamped with\n",
    "                # npy files\n",
    "                proceed = not check_workers_alive_and_busy(export_pool, worker_list, r, allowed_num_queued=2)\n",
    "                while not proceed:\n",
    "                    sleep(0.1)\n",
    "                    proceed = not check_workers_alive_and_busy(export_pool, worker_list, r, allowed_num_queued=2)\n",
    "\n",
    "                prediction = self.predict_logits_from_preprocessed_data(data).cpu()\n",
    "\n",
    "                if ofile is not None:\n",
    "                    # this needs to go into background processes\n",
    "                    # export_prediction_from_logits(prediction, properties, self.configuration_manager, self.plans_manager,\n",
    "                    #                               self.dataset_json, ofile, save_probabilities)\n",
    "                    print('sending off prediction to background worker for resampling and export')\n",
    "                    r.append(\n",
    "                        export_pool.starmap_async(\n",
    "                            export_prediction_from_logits,\n",
    "                            ((prediction, properties, self.configuration_manager, self.plans_manager,\n",
    "                              self.dataset_json, ofile, save_probabilities),)\n",
    "                        )\n",
    "                    )\n",
    "                else:\n",
    "                    # convert_predicted_logits_to_segmentation_with_correct_shape(\n",
    "                    #             prediction, self.plans_manager,\n",
    "                    #              self.configuration_manager, self.label_manager,\n",
    "                    #              properties,\n",
    "                    #              save_probabilities)\n",
    "\n",
    "                    print('sending off prediction to background worker for resampling')\n",
    "                    r.append(\n",
    "                        export_pool.starmap_async(\n",
    "                            convert_predicted_logits_to_segmentation_with_correct_shape, (\n",
    "                                (prediction, self.plans_manager,\n",
    "                                 self.configuration_manager, self.label_manager,\n",
    "                                 properties,\n",
    "                                 save_probabilities),)\n",
    "                        )\n",
    "                    )\n",
    "                if ofile is not None:\n",
    "                    print(f'done with {os.path.basename(ofile)}')\n",
    "                else:\n",
    "                    print(f'\\nDone with image of shape {data.shape}:')\n",
    "            ret = [i.get()[0] for i in r]\n",
    "\n",
    "        if isinstance(data_iterator, MultiThreadedAugmenter):\n",
    "            data_iterator._finish()\n",
    "\n",
    "        # clear lru cache\n",
    "        compute_gaussian.cache_clear()\n",
    "        # clear device cache\n",
    "        empty_cache(self.device)\n",
    "        return ret\n",
    "\n",
    "    def predict_single_npy_array(self, input_image: np.ndarray, image_properties: dict,\n",
    "                                 segmentation_previous_stage: np.ndarray = None,\n",
    "                                 output_file_truncated: str = None,\n",
    "                                 save_or_return_probabilities: bool = False):\n",
    "        \"\"\"\n",
    "        WARNING: SLOW. ONLY USE THIS IF YOU CANNOT GIVE NNUNET MULTIPLE IMAGES AT ONCE FOR SOME REASON.\n",
    "\n",
    "\n",
    "        input_image: Make sure to load the image in the way nnU-Net expects! nnU-Net is trained on a certain axis\n",
    "                     ordering which cannot be disturbed in inference,\n",
    "                     otherwise you will get bad results. The easiest way to achieve that is to use the same I/O class\n",
    "                     for loading images as was used during nnU-Net preprocessing! You can find that class in your\n",
    "                     plans.json file under the key \"image_reader_writer\". If you decide to freestyle, know that the\n",
    "                     default axis ordering for medical images is the one from SimpleITK. If you load with nibabel,\n",
    "                     you need to transpose your axes AND your spacing from [x,y,z] to [z,y,x]!\n",
    "        image_properties must only have a 'spacing' key!\n",
    "        \"\"\"\n",
    "        ppa = PreprocessAdapterFromNpy([input_image], [segmentation_previous_stage], [image_properties],\n",
    "                                       [output_file_truncated],\n",
    "                                       self.plans_manager, self.dataset_json, self.configuration_manager,\n",
    "                                       num_threads_in_multithreaded=1, verbose=self.verbose)\n",
    "        if self.verbose:\n",
    "            print('preprocessing')\n",
    "        dct = next(ppa)\n",
    "\n",
    "        if self.verbose:\n",
    "            print('predicting')\n",
    "        predicted_logits = self.predict_logits_from_preprocessed_data(dct['data']).cpu()\n",
    "\n",
    "        if self.verbose:\n",
    "            print('resampling to original shape')\n",
    "        if output_file_truncated is not None:\n",
    "            export_prediction_from_logits(predicted_logits, dct['data_properties'], self.configuration_manager,\n",
    "                                          self.plans_manager, self.dataset_json, output_file_truncated,\n",
    "                                          save_or_return_probabilities)\n",
    "        else:\n",
    "            ret = convert_predicted_logits_to_segmentation_with_correct_shape(predicted_logits, self.plans_manager,\n",
    "                                                                              self.configuration_manager,\n",
    "                                                                              self.label_manager,\n",
    "                                                                              dct['data_properties'],\n",
    "                                                                              return_probabilities=\n",
    "                                                                              save_or_return_probabilities)\n",
    "            if save_or_return_probabilities:\n",
    "                return ret[0], ret[1]\n",
    "            else:\n",
    "                return ret\n",
    "\n",
    "    def predict_logits_from_preprocessed_data(self, data: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        IMPORTANT! IF YOU ARE RUNNING THE CASCADE, THE SEGMENTATION FROM THE PREVIOUS STAGE MUST ALREADY BE STACKED ON\n",
    "        TOP OF THE IMAGE AS ONE-HOT REPRESENTATION! SEE PreprocessAdapter ON HOW THIS SHOULD BE DONE!\n",
    "\n",
    "        RETURNED LOGITS HAVE THE SHAPE OF THE INPUT. THEY MUST BE CONVERTED BACK TO THE ORIGINAL IMAGE SIZE.\n",
    "        SEE convert_predicted_logits_to_segmentation_with_correct_shape\n",
    "        \"\"\"\n",
    "        n_threads = torch.get_num_threads()\n",
    "        torch.set_num_threads(default_num_processes if default_num_processes < n_threads else n_threads)\n",
    "        prediction = None\n",
    "\n",
    "        for params in self.list_of_parameters:\n",
    "\n",
    "            # messing with state dict names...\n",
    "            if not isinstance(self.network, OptimizedModule):\n",
    "                self.network.load_state_dict(params)\n",
    "            else:\n",
    "                self.network._orig_mod.load_state_dict(params)\n",
    "\n",
    "            # why not leave prediction on device if perform_everything_on_device? Because this may cause the\n",
    "            # second iteration to crash due to OOM. Grabbing that with try except cause way more bloated code than\n",
    "            # this actually saves computation time\n",
    "            if prediction is None:\n",
    "                prediction = self.predict_sliding_window_return_logits(data).to('cpu')\n",
    "            else:\n",
    "                prediction += self.predict_sliding_window_return_logits(data).to('cpu')\n",
    "\n",
    "        if len(self.list_of_parameters) > 1:\n",
    "            prediction /= len(self.list_of_parameters)\n",
    "\n",
    "        if self.verbose: print('Prediction done')\n",
    "        torch.set_num_threads(n_threads)\n",
    "        return prediction\n",
    "\n",
    "    def _internal_get_sliding_window_slicers(self, image_size: Tuple[int, ...]):\n",
    "        slicers = []\n",
    "        if len(self.configuration_manager.patch_size) < len(image_size):\n",
    "            assert len(self.configuration_manager.patch_size) == len(\n",
    "                image_size) - 1, 'if tile_size has less entries than image_size, ' \\\n",
    "                                 'len(tile_size) ' \\\n",
    "                                 'must be one shorter than len(image_size) ' \\\n",
    "                                 '(only dimension ' \\\n",
    "                                 'discrepancy of 1 allowed).'\n",
    "            steps = compute_steps_for_sliding_window(image_size[1:], self.configuration_manager.patch_size,\n",
    "                                                     self.tile_step_size)\n",
    "            if self.verbose: print(f'n_steps {image_size[0] * len(steps[0]) * len(steps[1])}, image size is'\n",
    "                                   f' {image_size}, tile_size {self.configuration_manager.patch_size}, '\n",
    "                                   f'tile_step_size {self.tile_step_size}\\nsteps:\\n{steps}')\n",
    "            for d in range(image_size[0]):\n",
    "                for sx in steps[0]:\n",
    "                    for sy in steps[1]:\n",
    "                        slicers.append(\n",
    "                            tuple([slice(None), d, *[slice(si, si + ti) for si, ti in\n",
    "                                                     zip((sx, sy), self.configuration_manager.patch_size)]]))\n",
    "        else:\n",
    "            steps = compute_steps_for_sliding_window(image_size, self.configuration_manager.patch_size,\n",
    "                                                     self.tile_step_size)\n",
    "            if self.verbose: print(\n",
    "                f'n_steps {np.prod([len(i) for i in steps])}, image size is {image_size}, tile_size {self.configuration_manager.patch_size}, '\n",
    "                f'tile_step_size {self.tile_step_size}\\nsteps:\\n{steps}')\n",
    "            for sx in steps[0]:\n",
    "                for sy in steps[1]:\n",
    "                    for sz in steps[2]:\n",
    "                        slicers.append(\n",
    "                            tuple([slice(None), *[slice(si, si + ti) for si, ti in\n",
    "                                                  zip((sx, sy, sz), self.configuration_manager.patch_size)]]))\n",
    "        return slicers\n",
    "\n",
    "        \n",
    "    def _internal_maybe_mirror_and_predict(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        mirror_axes = self.allowed_mirroring_axes if self.use_mirroring else None\n",
    "        prediction = self.network1(x)\n",
    "        \n",
    "        if mirror_axes is not None:\n",
    "            # check for invalid numbers in mirror_axes\n",
    "            # x should be 5d for 3d images and 4d for 2d. so the max value of mirror_axes cannot exceed len(x.shape) - 3\n",
    "            assert max(mirror_axes) <= x.ndim - 3, 'mirror_axes does not match the dimension of the input!'\n",
    "\n",
    "            mirror_axes = [m + 2 for m in mirror_axes]\n",
    "            axes_combinations = [\n",
    "                c for i in range(len(mirror_axes)) for c in itertools.combinations(mirror_axes, i + 1)\n",
    "            ]\n",
    "            for axes in axes_combinations:\n",
    "                prediction += torch.flip(self.network1(torch.flip(x, axes)), axes)\n",
    "            prediction /= (len(axes_combinations) + 1)\n",
    "        return prediction\n",
    "\n",
    "    def _internal_predict_sliding_window_return_logits(self,\n",
    "                                                       data: torch.Tensor,\n",
    "                                                       slicers,\n",
    "                                                       do_on_device: bool = True,\n",
    "                                                       ):\n",
    "        predicted_logits = n_predictions = prediction = gaussian = workon = None\n",
    "        results_device = self.device if do_on_device else torch.device('cpu')\n",
    "\n",
    "        try:\n",
    "            empty_cache(self.device)\n",
    "\n",
    "            # move data to device\n",
    "            if self.verbose:\n",
    "                print(f'move image to device {results_device}')\n",
    "            data = data.to(results_device)\n",
    "\n",
    "            # preallocate arrays\n",
    "            if self.verbose:\n",
    "                print(f'preallocating results arrays on device {results_device}')\n",
    "            predicted_logits = torch.zeros((self.label_manager.num_segmentation_heads, *data.shape[1:]),\n",
    "                                           dtype=torch.half,\n",
    "                                           device=results_device)\n",
    "            n_predictions = torch.zeros(data.shape[1:], dtype=torch.half, device=results_device)\n",
    "\n",
    "            if self.use_gaussian:\n",
    "                gaussian = compute_gaussian(tuple(self.configuration_manager.patch_size), sigma_scale=1. / 8,\n",
    "                                            value_scaling_factor=10,\n",
    "                                            device=results_device)\n",
    "            else:\n",
    "                gaussian = 1\n",
    "\n",
    "            if not self.allow_tqdm and self.verbose:\n",
    "                print(f'running prediction: {len(slicers)} steps')\n",
    "            for sl in tqdm(slicers, disable=not self.allow_tqdm):\n",
    "                workon = data[sl][None]\n",
    "                workon = workon.to(self.device)\n",
    "\n",
    "                prediction = self._internal_maybe_mirror_and_predict(workon)[0].to(results_device)\n",
    "\n",
    "                if self.use_gaussian:\n",
    "                    prediction *= gaussian\n",
    "                predicted_logits[sl] += prediction\n",
    "                n_predictions[sl[1:]] += gaussian\n",
    "\n",
    "            predicted_logits /= n_predictions\n",
    "            # check for infs\n",
    "            if torch.any(torch.isinf(predicted_logits)):\n",
    "                raise RuntimeError('Encountered inf in predicted array. Aborting... If this problem persists, '\n",
    "                                   'reduce value_scaling_factor in compute_gaussian or increase the dtype of '\n",
    "                                   'predicted_logits to fp32')\n",
    "        except Exception as e:\n",
    "            del predicted_logits, n_predictions, prediction, gaussian, workon\n",
    "            empty_cache(self.device)\n",
    "            empty_cache(results_device)\n",
    "            raise e\n",
    "        return predicted_logits\n",
    "\n",
    "    def predict_sliding_window_return_logits(self, input_image: torch.Tensor) \\\n",
    "            -> Union[np.ndarray, torch.Tensor]:\n",
    "        with torch.no_grad():\n",
    "            assert isinstance(input_image, torch.Tensor)\n",
    "            self.network = self.network.to(self.device)\n",
    "            self.network.eval()\n",
    "\n",
    "            empty_cache(self.device)\n",
    "\n",
    "            # Autocast can be annoying\n",
    "            # If the device_type is 'cpu' then it's slow as heck on some CPUs (no auto bfloat16 support detection)\n",
    "            # and needs to be disabled.\n",
    "            # If the device_type is 'mps' then it will complain that mps is not implemented, even if enabled=False\n",
    "            # is set. Whyyyyyyy. (this is why we don't make use of enabled=False)\n",
    "            # So autocast will only be active if we have a cuda device.\n",
    "            with torch.autocast(self.device.type, enabled=True) if self.device.type == 'cuda' else dummy_context():\n",
    "                assert input_image.ndim == 4, 'input_image must be a 4D np.ndarray or torch.Tensor (c, x, y, z)'\n",
    "\n",
    "                if self.verbose:\n",
    "                    print(f'Input shape: {input_image.shape}')\n",
    "                    print(\"step_size:\", self.tile_step_size)\n",
    "                    print(\"mirror_axes:\", self.allowed_mirroring_axes if self.use_mirroring else None)\n",
    "\n",
    "                # if input_image is smaller than tile_size we need to pad it to tile_size.\n",
    "                data, slicer_revert_padding = pad_nd_image(input_image, self.configuration_manager.patch_size,\n",
    "                                                           'constant', {'value': 0}, True,\n",
    "                                                           None)\n",
    "\n",
    "                slicers = self._internal_get_sliding_window_slicers(data.shape[1:])\n",
    "\n",
    "                if self.perform_everything_on_device and self.device != 'cpu':\n",
    "                    # we need to try except here because we can run OOM in which case we need to fall back to CPU as a results device\n",
    "                    try:\n",
    "                        predicted_logits = self._internal_predict_sliding_window_return_logits(data, slicers,\n",
    "                                                                                               self.perform_everything_on_device)\n",
    "                    except RuntimeError:\n",
    "                        print(\n",
    "                            'Prediction on device was unsuccessful, probably due to a lack of memory. Moving results arrays to CPU')\n",
    "                        empty_cache(self.device)\n",
    "                        predicted_logits = self._internal_predict_sliding_window_return_logits(data, slicers, False)\n",
    "                else:\n",
    "                    predicted_logits = self._internal_predict_sliding_window_return_logits(data, slicers,\n",
    "                                                                                           self.perform_everything_on_device)\n",
    "\n",
    "                empty_cache(self.device)\n",
    "                # revert padding\n",
    "                predicted_logits = predicted_logits[(slice(None), *slicer_revert_padding[1:])]\n",
    "        print(predicted_logits.shape,torch.sum(predicted_logits>0,dim=[1,2,3]))\n",
    "        return predicted_logits\n",
    "\n",
    "\n",
    "def predict_entry_point_modelfolder():\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser(description='Use this to run inference with nnU-Net. This function is used when '\n",
    "                                                 'you want to manually specify a folder containing a trained nnU-Net '\n",
    "                                                 'model. This is useful when the nnunet environment variables '\n",
    "                                                 '(nnUNet_results) are not set.')\n",
    "    parser.add_argument('-i', type=str, required=True,\n",
    "                        help='input folder. Remember to use the correct channel numberings for your files (_0000 etc). '\n",
    "                             'File endings must be the same as the training dataset!')\n",
    "    parser.add_argument('-o', type=str, required=True,\n",
    "                        help='Output folder. If it does not exist it will be created. Predicted segmentations will '\n",
    "                             'have the same name as their source images.')\n",
    "    parser.add_argument('-m', type=str, required=True,\n",
    "                        help='Folder in which the trained model is. Must have subfolders fold_X for the different '\n",
    "                             'folds you trained')\n",
    "    parser.add_argument('-f', nargs='+', type=str, required=False, default=(0, 1, 2, 3, 4),\n",
    "                        help='Specify the folds of the trained model that should be used for prediction. '\n",
    "                             'Default: (0, 1, 2, 3, 4)')\n",
    "    parser.add_argument('-step_size', type=float, required=False, default=0.5,\n",
    "                        help='Step size for sliding window prediction. The larger it is the faster but less accurate '\n",
    "                             'the prediction. Default: 0.5. Cannot be larger than 1. We recommend the default.')\n",
    "    parser.add_argument('--disable_tta', action='store_true', required=False, default=False,\n",
    "                        help='Set this flag to disable test time data augmentation in the form of mirroring. Faster, '\n",
    "                             'but less accurate inference. Not recommended.')\n",
    "    parser.add_argument('--verbose', action='store_true', help=\"Set this if you like being talked to. You will have \"\n",
    "                                                               \"to be a good listener/reader.\")\n",
    "    parser.add_argument('--save_probabilities', action='store_true',\n",
    "                        help='Set this to export predicted class \"probabilities\". Required if you want to ensemble '\n",
    "                             'multiple configurations.')\n",
    "    parser.add_argument('--continue_prediction', '--c', action='store_true',\n",
    "                        help='Continue an aborted previous prediction (will not overwrite existing files)')\n",
    "    parser.add_argument('-chk', type=str, required=False, default='checkpoint_final.pth',\n",
    "                        help='Name of the checkpoint you want to use. Default: checkpoint_final.pth')\n",
    "    parser.add_argument('-npp', type=int, required=False, default=3,\n",
    "                        help='Number of processes used for preprocessing. More is not always better. Beware of '\n",
    "                             'out-of-RAM issues. Default: 3')\n",
    "    parser.add_argument('-nps', type=int, required=False, default=3,\n",
    "                        help='Number of processes used for segmentation export. More is not always better. Beware of '\n",
    "                             'out-of-RAM issues. Default: 3')\n",
    "    parser.add_argument('-prev_stage_predictions', type=str, required=False, default=None,\n",
    "                        help='Folder containing the predictions of the previous stage. Required for cascaded models.')\n",
    "    parser.add_argument('-device', type=str, default='cuda', required=False,\n",
    "                        help=\"Use this to set the device the inference should run with. Available options are 'cuda' \"\n",
    "                             \"(GPU), 'cpu' (CPU) and 'mps' (Apple M1/M2). Do NOT use this to set which GPU ID! \"\n",
    "                             \"Use CUDA_VISIBLE_DEVICES=X nnUNetv2_predict [...] instead!\")\n",
    "    parser.add_argument('--disable_progress_bar', action='store_true', required=False, default=False,\n",
    "                        help='Set this flag to disable progress bar. Recommended for HPC environments (non interactive '\n",
    "                             'jobs)')\n",
    "\n",
    "    print(\n",
    "        \"\\n#######################################################################\\nPlease cite the following paper \"\n",
    "        \"when using nnU-Net:\\n\"\n",
    "        \"Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). \"\n",
    "        \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. \"\n",
    "        \"Nature methods, 18(2), 203-211.\\n#######################################################################\\n\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    args.f = [i if i == 'all' else int(i) for i in args.f]\n",
    "\n",
    "    if not isdir(args.o):\n",
    "        maybe_mkdir_p(args.o)\n",
    "\n",
    "    assert args.device in ['cpu', 'cuda',\n",
    "                           'mps'], f'-device must be either cpu, mps or cuda. Other devices are not tested/supported. Got: {args.device}.'\n",
    "    if args.device == 'cpu':\n",
    "        # let's allow torch to use hella threads\n",
    "        import multiprocessing\n",
    "        torch.set_num_threads(multiprocessing.cpu_count())\n",
    "        device = torch.device('cpu')\n",
    "    elif args.device == 'cuda':\n",
    "        # multithreading in torch doesn't help nnU-Net if run on GPU\n",
    "        torch.set_num_threads(1)\n",
    "        torch.set_num_interop_threads(1)\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('mps')\n",
    "\n",
    "    predictor = nnUNetPredictor(tile_step_size=args.step_size,\n",
    "                                use_gaussian=True,\n",
    "                                use_mirroring=not args.disable_tta,\n",
    "                                perform_everything_on_device=True,\n",
    "                                device=device,\n",
    "                                verbose=args.verbose,\n",
    "                                allow_tqdm=not args.disable_progress_bar,\n",
    "                                verbose_preprocessing=args.verbose)\n",
    "    predictor.initialize_from_trained_model_folder(args.m, args.f, args.chk)\n",
    "    predictor.predict_from_files(args.i, args.o, save_probabilities=args.save_probabilities,\n",
    "                                 overwrite=not args.continue_prediction,\n",
    "                                 num_processes_preprocessing=args.npp,\n",
    "                                 num_processes_segmentation_export=args.nps,\n",
    "                                 folder_with_segs_from_prev_stage=args.prev_stage_predictions,\n",
    "                                 num_parts=1, part_id=0)\n",
    "\n",
    "\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser(description='Use this to run inference with nnU-Net. This function is used when '\n",
    "                                             'you want to manually specify a folder containing a trained nnU-Net '\n",
    "                                             'model. This is useful when the nnunet environment variables '\n",
    "                                             '(nnUNet_results) are not set.')\n",
    "parser.add_argument('-i', type=str, required=False, default='D:/Datasets/nnUNet_raw/Dataset316_CathAction/imagesTs',\n",
    "                    help='input folder. Remember to use the correct channel numberings for your files (_0000 etc). '\n",
    "                         'File endings must be the same as the training dataset!')\n",
    "parser.add_argument('-o', type=str, required=False, default='D:/Datasets/cathaction/results/MSLNet',\n",
    "                    help='Output folder. If it does not exist it will be created. Predicted segmentations will '\n",
    "                         'have the same name as their source images.')\n",
    "parser.add_argument('-d', type=str, required=False, default='316',\n",
    "                    help='Dataset with which you would like to predict. You can specify either dataset name or id')\n",
    "parser.add_argument('-p', type=str, required=False, default='nnUNetPlans',\n",
    "                    help='Plans identifier. Specify the plans in which the desired configuration is located. '\n",
    "                         'Default: nnUNetPlans')\n",
    "parser.add_argument('-tr', type=str, required=False, default='nnUNetTrainer',\n",
    "                    help='What nnU-Net trainer class was used for training? Default: nnUNetTrainer')\n",
    "parser.add_argument('-c', type=str, required=False, default='2d',\n",
    "                    help='nnU-Net configuration that should be used for prediction. Config must be located '\n",
    "                         'in the plans specified with -p')\n",
    "parser.add_argument('-f', nargs='+', type=str, required=False, default='1',\n",
    "                    help='Specify the folds of the trained model that should be used for prediction. '\n",
    "                         'Default: (0, 1, 2, 3, 4)')\n",
    "parser.add_argument('-step_size', type=float, required=False, default=0.5,\n",
    "                    help='Step size for sliding window prediction. The larger it is the faster but less accurate '\n",
    "                         'the prediction. Default: 0.5. Cannot be larger than 1. We recommend the default.')\n",
    "parser.add_argument('--disable_tta', action='store_true', required=False, default=False,\n",
    "                    help='Set this flag to disable test time data augmentation in the form of mirroring. Faster, '\n",
    "                         'but less accurate inference. Not recommended.')\n",
    "parser.add_argument('--verbose', action='store_true', help=\"Set this if you like being talked to. You will have \"\n",
    "                                                           \"to be a good listener/reader.\")\n",
    "parser.add_argument('--save_probabilities', action='store_true',\n",
    "                    help='Set this to export predicted class \"probabilities\". Required if you want to ensemble '\n",
    "                         'multiple configurations.')\n",
    "parser.add_argument('--continue_prediction', action='store_true',\n",
    "                    help='Continue an aborted previous prediction (will not overwrite existing files)')\n",
    "parser.add_argument('-chk', type=str, required=False, default='checkpoint_final.pth',\n",
    "                    help='Name of the checkpoint you want to use. Default: checkpoint_final.pth')\n",
    "parser.add_argument('-npp', type=int, required=False, default=3,\n",
    "                    help='Number of processes used for preprocessing. More is not always better. Beware of '\n",
    "                         'out-of-RAM issues. Default: 3')\n",
    "parser.add_argument('-nps', type=int, required=False, default=3,\n",
    "                    help='Number of processes used for segmentation export. More is not always better. Beware of '\n",
    "                         'out-of-RAM issues. Default: 3')\n",
    "parser.add_argument('-prev_stage_predictions', type=str, required=False, default=None,\n",
    "                    help='Folder containing the predictions of the previous stage. Required for cascaded models.')\n",
    "parser.add_argument('-num_parts', type=int, required=False, default=1,\n",
    "                    help='Number of separate nnUNetv2_predict call that you will be making. Default: 1 (= this one '\n",
    "                         'call predicts everything)')\n",
    "parser.add_argument('-part_id', type=int, required=False, default=0,\n",
    "                    help='If multiple nnUNetv2_predict exist, which one is this? IDs start with 0 can end with '\n",
    "                         'num_parts - 1. So when you submit 5 nnUNetv2_predict calls you need to set -num_parts '\n",
    "                         '5 and use -part_id 0, 1, 2, 3 and 4. Simple, right? Note: You are yourself responsible '\n",
    "                         'to make these run on separate GPUs! Use CUDA_VISIBLE_DEVICES (google, yo!)')\n",
    "parser.add_argument('-device', type=str, default='cuda', required=False,\n",
    "                    help=\"Use this to set the device the inference should run with. Available options are 'cuda' \"\n",
    "                         \"(GPU), 'cpu' (CPU) and 'mps' (Apple M1/M2). Do NOT use this to set which GPU ID! \"\n",
    "                         \"Use CUDA_VISIBLE_DEVICES=X nnUNetv2_predict [...] instead!\")\n",
    "parser.add_argument('--disable_progress_bar', action='store_true', required=False, default=False,\n",
    "                    help='Set this flag to disable progress bar. Recommended for HPC environments (non interactive '\n",
    "                         'jobs)')\n",
    "\n",
    "print(\n",
    "    \"\\n#######################################################################\\nPlease cite the following paper \"\n",
    "    \"when using nnU-Net:\\n\"\n",
    "    \"Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). \"\n",
    "    \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. \"\n",
    "    \"Nature methods, 18(2), 203-211.\\n#######################################################################\\n\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "args.f = '0'#[i if i == 'all' else int(i) for i in args.f]\n",
    "\n",
    "args.o=args.o+'_%s/'%args.f\n",
    "#'D:\\\\Datasets\\\\nnUNet_results\\\\Dataset316_CathAction\\\\nnUNetTrainer__nnUNetPlans__2d'\n",
    "model_folder = get_output_folder(args.d, args.tr, args.p, args.c)\n",
    "\n",
    "if not isdir(args.o):\n",
    "    maybe_mkdir_p(args.o)\n",
    "\n",
    "# slightly passive aggressive haha\n",
    "assert args.part_id < args.num_parts, 'Do you even read the documentation? See nnUNetv2_predict -h.'\n",
    "\n",
    "assert args.device in ['cpu', 'cuda',\n",
    "                       'mps'], f'-device must be either cpu, mps or cuda. Other devices are not tested/supported. Got: {args.device}.'\n",
    "if args.device == 'cpu':\n",
    "    # let's allow torch to use hella threads\n",
    "    import multiprocessing\n",
    "    torch.set_num_threads(multiprocessing.cpu_count())\n",
    "    device = torch.device('cpu')\n",
    "elif args.device == 'cuda':\n",
    "    # multithreading in torch doesn't help nnU-Net if run on GPU\n",
    "    torch.set_num_threads(1)\n",
    "    torch.set_num_interop_threads(1)\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('mps')\n",
    "\n",
    "predictor = nnUNetPredictor(tile_step_size=args.step_size,\n",
    "                            use_gaussian=True,\n",
    "                            use_mirroring=not args.disable_tta,\n",
    "                            perform_everything_on_device=True,\n",
    "                            device=device,\n",
    "                            verbose=args.verbose,\n",
    "                            verbose_preprocessing=args.verbose,\n",
    "                            allow_tqdm=not args.disable_progress_bar)\n",
    "predictor.initialize_from_trained_model_folder(\n",
    "    model_folder,\n",
    "    args.f,\n",
    "    checkpoint_name=args.chk\n",
    ")\n",
    "a=predictor.predict_from_files(args.i, args.o, save_probabilities=args.save_probabilities,\n",
    "                             overwrite=not args.continue_prediction,\n",
    "                             num_processes_preprocessing=args.npp,\n",
    "                             num_processes_segmentation_export=args.nps,\n",
    "                             folder_with_segs_from_prev_stage=args.prev_stage_predictions,\n",
    "                             num_parts=args.num_parts,\n",
    "                             part_id=args.part_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in nnunet_trainer.network.parameters():\n",
    "    s=torch.sum(torch.isnan(p))\n",
    "    if s>0:\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
