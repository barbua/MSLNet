{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g5allA7N47RG",
    "outputId": "29c71e2e-65d7-4f85-9675-89f7c5c10082"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Fn\n",
    "import torchvision.transforms.functional as vF\n",
    "from time import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.io.image import read_image\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, RandomCrop,ToTensor, Normalize, Grayscale, RandomRotation\n",
    "from torchvision.transforms.v2 import  RandomResize\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "from torchvision.io.image import read_image,write_png\n",
    "from scipy.io import loadmat,savemat\n",
    "from skimage.draw import line\n",
    "from scipy import ndimage\n",
    "\n",
    "from PIL import Image\n",
    "from MSLNet import log2file\n",
    "from scipy import ndimage\n",
    "\n",
    "try:\n",
    "    from torchvision.transforms import InterpolationMode\n",
    "    BICUBIC = InterpolationMode.BICUBIC\n",
    "except ImportError:\n",
    "    BICUBIC = Image.BICUBIC # resize the input image using bicubic interpolation, producing a smoother result compared to other interpolation methods like device = torch.device(\"cuda\")\n",
    "\n",
    "def load_image(name, method='PIL'):\n",
    "    t=ToTensor()\n",
    "    if method=='PIL':\n",
    "        x = t(Image.open(name))\n",
    "    else:\n",
    "        x = read_image(name)\n",
    "    #print(x.shape)\n",
    "    return x\n",
    "\n",
    "def iou1(a,b):\n",
    "    \"\"\"\n",
    "    Function to get the IOU between two 1D-tensors\n",
    "    \"\"\"\n",
    "    io=torch.sum(a*b)/(torch.sum(torch.max(a,b))+0.00001)\n",
    "    return io\n",
    "\n",
    "def Dice(a,b):\n",
    "    return 2*torch.sum(a*b)/(torch.sum(a)+torch.sum(b))\n",
    "\n",
    "def load_mask1(path,name):\n",
    "    yi=np.load(path+'masks/'+name+'.npy')\n",
    "    return torch.tensor(yi>0).float()\n",
    "\n",
    "def load_mask(path,name):\n",
    "    t=ToTensor()\n",
    "    x = t(Image.open(path+'masks/1-7/'+name+'.png'))\n",
    "    return x.squeeze(0)\n",
    "\n",
    "def keeponly(names,st):\n",
    "    out=[]\n",
    "    for name in names:\n",
    "        if st in name:\n",
    "            out.append(name)\n",
    "    return out\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#device = 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='d:/datasets/cathaction/'\n",
    "with open(path+'train.txt', 'r') as f:\n",
    "    train = f.read().splitlines()\n",
    "with open(path+'test.txt', 'r') as f:\n",
    "    test = f.read().splitlines()\n",
    "#test=keeponly(test,'pt')\n",
    "print(len(train),len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import thin,medial_axis,skeletonize\n",
    "def precision(a,dy):\n",
    "    ndet=np.sum(a) # detections\n",
    "    ncdet=np.sum(a*dy) \n",
    "    prec=ncdet/(ndet+0.00001)\n",
    "    return prec.item()\n",
    "\n",
    "def recall(dr,y):\n",
    "    npos=np.sum(y>0).item() # positives\n",
    "    npdet=np.sum((y*dr)>0).item() # detected positives, with detection at dist <=2\n",
    "    rec=npdet/(npos+0.00001)\n",
    "    #print(npos,npdet,rec)\n",
    "    return rec\n",
    "\n",
    "def eval1(da,dy,dist):\n",
    "    # y= GT\n",
    "    # dGt = dt of GT\n",
    "    # xr = result\n",
    "    dr=da<=dist\n",
    "    prec=precision(da==0,dy<=dist)\n",
    "    rec=recall(dr,dy==0)    \n",
    "    return prec,rec\n",
    "\n",
    "def AHD(da,dy):\n",
    "    day=da[dy==0]\n",
    "    dya=dy[da==0]\n",
    "    return (np.mean(day)+np.mean(dya)).item()/2\n",
    "\n",
    "# evaluate the runs of a method\n",
    "bases=['MslLorNN_']\n",
    "for base in bases:\n",
    "    names=[]\n",
    "    for i in range(4):\n",
    "        name='%s%d'%(base,i)\n",
    "        names.append(name)\n",
    "    print(names)\n",
    "    n=len(test)\n",
    "    nclf=len(names)\n",
    "    allp=np.zeros((n,nclf))\n",
    "    allr=np.zeros((n,nclf))\n",
    "    ious=np.zeros((n,nclf))\n",
    "    dices=np.zeros((n,nclf))\n",
    "    ahds=np.zeros((n,nclf))\n",
    "    valid=np.ones((n,nclf),dtype=np.int32)\n",
    "    thr=0\n",
    "    for i in range(n):\n",
    "        yi=load_mask1(path,test[i])\n",
    "        yi=torch.tensor(thin(yi>0)).float()\n",
    "        dy=ndimage.distance_transform_edt(1-yi)\n",
    "        nr,nc=yi.shape\n",
    "        for j in range(nclf):\n",
    "            paths=path+'Resultsloc/'+names[j]+'/'+test[i]+'.png'\n",
    "            if not os.path.exists(paths):\n",
    "                print(paths,'not found')\n",
    "                valid[i,j]=0\n",
    "                continue\n",
    "            xr=load_image(paths).squeeze()*255\n",
    "            if len(xr.shape)>2:\n",
    "                xr=xr[0,:,:]\n",
    "            #print(torch.max(xr))\n",
    "            xr=(xr[:nr,:nc]>thr).float()\n",
    "            dx=ndimage.distance_transform_edt(1-xr)\n",
    "            p,r=eval1(dx,dy,0)\n",
    "            dices[i,j]=Dice(yi,xr)\n",
    "            ious[i,j]=iou1(yi,xr)\n",
    "            ahds[i,j]=AHD(dx,dy)\n",
    "            allp[i,j]=p\n",
    "            allr[i,j]=r\n",
    "            #print(i,j,p,r)\n",
    "        if i%200==0:\n",
    "            p,r=np.mean(allp[:i+1,0]),np.mean(allr[:i+1,0])\n",
    "            d,io=np.mean(dices[:i+1,0]),np.mean(ious[:i+1,0])\n",
    "            ahd=np.mean(ahds[:i+1,0])\n",
    "            f=2*p*r/(p+r)\n",
    "            print('%d %1.2f %1.2f %1.2f %1.2f %1.2f %.1f'%(i,p*100,r*100,f*100,d*100,io*100,ahd))\n",
    "    p,r,f,d,io,ahd=[],[],[],[],[],[]\n",
    "    for j in range(nclf):\n",
    "        p.append(np.mean(allp[valid[:,j]==1,j])*100)\n",
    "        r.append(np.mean(allr[valid[:,j]==1,j])*100)\n",
    "        d.append(np.mean(dices[valid[:,j]==1,j])*100)\n",
    "        io.append(np.mean(ious[valid[:,j]==1,j])*100) \n",
    "        ahd.append(np.mean(ahds[(valid[:,j]==1)&(np.isnan(ahds[:,j])==False),j])) \n",
    "        f.append(2*p[j]*r[j]/(p[j]+r[j]))\n",
    "        log2file('evalloc.txt','%s %.2f %1.2f %1.2f %1.2f %1.2f %1.2f %.1f'%(names[j],thr,p[j],r[j],f[j],d[j],io[j],ahd[j]))\n",
    "    if len(p)>1:\n",
    "        log2file('evalloc.txt','%.2f &%1.2f (%.2f) &%1.2f (%.2f) &%1.2f (%1.2f) &%1.2f (%1.2f) &%1.2f (%1.2f) &%1.1f (%1.1f)'%(thr,np.mean(p),np.std(p),np.mean(r),np.std(r),np.mean(f),np.std(f),np.mean(d),np.std(d),np.mean(io),np.std(io),np.mean(ahd),np.std(ahd)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make all results have value 255\n",
    "import glob\n",
    "#pathseg='D:\\\\Datasets\\\\CathAction\\\\Results\\\\SwinCA_2\\\\'\n",
    "#pathseg='D:\\\\Datasets\\\\CathAction\\\\masks\\\\'\n",
    "t=ToTensor()\n",
    "os.chdir(pathseg) \n",
    "files = glob.glob(\"*.png\")\n",
    "#files = [f for f in os.listdir(pathseg) if os.path.isfile(os.path.join(pathseg, f))]\n",
    "for i in range(len(files)):\n",
    "    name=pathseg+files[i]\n",
    "    im = t(Image.open(name))\n",
    "    im1 = (im*255**2).long()\n",
    "    #name=pathseg+files[i][:-4]+'.png'\n",
    "    write_png(im1.to(torch.uint8),name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine results with masks\n",
    "from utils_MSL import merge\n",
    "import glob\n",
    "path='D:\\\\Datasets\\\\CathAction\\\\'\n",
    "pathano=path+'masks\\\\'\n",
    "todo='SwinCA_0'\n",
    "pathseg=path+'Results\\\\'+todo\n",
    "pathout=path+'ResultsAno\\\\'+todo\n",
    "os.makedirs(pathout, exist_ok=True)\n",
    "t=ToTensor()\n",
    "os.chdir(pathseg) \n",
    "files = glob.glob(\"*.png\")\n",
    "#files = [f for f in os.listdir(pathseg) if os.path.isfile(os.path.join(pathseg, f))]\n",
    "for i in range(len(files)):\n",
    "    name=pathseg+'\\\\'+files[i]\n",
    "    im = t(Image.open(name)).squeeze()\n",
    "    if len(im.shape)>2:\n",
    "        im=im[0,:,:]\n",
    "    name=pathano+files[i]\n",
    "    ano = t(Image.open(name)).squeeze()\n",
    "    im=(im>0/255).float()\n",
    "    out=merge([ano,im])\n",
    "    im1 = (out*255).long().permute(2,0,1)\n",
    "    name=pathout+'\\\\'+files[i]\n",
    "    write_png(im1.to(torch.uint8),name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run Ambrosini's TACE centerline extraction and grouping program\n",
    "import subprocess\n",
    "path='D:\\\\Datasets\\\\CathAction\\\\'\n",
    "pathexe='../../CNN-2D-X-Ray-Catheter-Detection\\\\cpp\\\\Release\\\\tace.exe'\n",
    "pathseg=path+'Results\\\\SwinCA_0\\\\'\n",
    "pathloc=path+'Results_loc\\\\SwinCA_0\\\\'\n",
    "os.makedirs(pathloc, exist_ok=True)\n",
    "for i in range(len(test)):\n",
    "    subprocess.run([pathexe, pathseg+test[i]+'.png',pathloc+test[i]+'.txt'])\n",
    "    if i%1000==0:\n",
    "        print(i,end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load curves from text files and save them as images\n",
    "def draw(m,p):\n",
    "    nc,nr=m.shape\n",
    "    p=np.round(p).astype(np.int32)\n",
    "    for i in range(1,p.shape[0]):\n",
    "        r,c = line(p[i-1,0],p[i-1,1],p[i,0],p[i,1])\n",
    "        r1=r[(r<nr)&(c<nc)]\n",
    "        c1=c[(r<nr)&(c<nc)]\n",
    "        m[c1,r1]=1\n",
    "    return m\n",
    "path='D:\\\\Datasets\\\\CathAction\\\\'\n",
    "pathseg=path+'Results\\\\SwinCA_3\\\\'\n",
    "pathloc=path+'Results_loc\\\\SwinCA_3\\\\'\n",
    "for i in range(len(test)):\n",
    "    name=pathseg+test[i]+'.png'\n",
    "    im = Image.open(name)\n",
    "    nc,nr=im.size\n",
    "    #print(nr,nc)\n",
    "    m=torch.zeros(nr,nc)\n",
    "    name=pathloc+test[i]+'.txt'\n",
    "    if os.path.isfile(name):\n",
    "        cv=np.loadtxt(name)\n",
    "        if len(cv.shape)>=2:\n",
    "            m=draw(m,cv)\n",
    "            m=m*255\n",
    "    #print(m.shape,l.shape)\n",
    "    #plt.imshow(m,cmap='gray')\n",
    "    name=pathloc+test[i]+'.png'\n",
    "    write_png(m.unsqueeze(0).to(torch.uint8),name)\n",
    "    if i%1000==0:\n",
    "        print(i,end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluate on a sequence level\n",
    "from utils_MSL import log2file\n",
    "from scipy import ndimage\n",
    "import os\n",
    "   \n",
    "def load_masks(path,seq,ext,dothin=0):\n",
    "    t=ToTensor()\n",
    "    ys=[]\n",
    "    dts=[]\n",
    "    for n in seq:\n",
    "        yi=load_mask(path,n)\n",
    "        if dothin:\n",
    "            yi=torch.tensor(thin(yi>0)).float()\n",
    "        #print(x.shape)\n",
    "        dy=ndimage.distance_transform_edt(1-yi)\n",
    "        ys.append(yi)\n",
    "        dts.append(dy)\n",
    "    return ys,dts\n",
    "\n",
    "def load_images(path,seq,ext,channel=0,method='PIL'):\n",
    "    t=ToTensor()\n",
    "    im=[]\n",
    "    for n in seq:\n",
    "        name=path+'/'+n+ext\n",
    "        if os.path.exists(name)==False:\n",
    "            print('not found',name)\n",
    "            continue\n",
    "        if method=='PIL':\n",
    "            x = t(Image.open(name))*255\n",
    "        else:\n",
    "            x = read_image(name)*255\n",
    "        #print(x.shape)\n",
    "        if len(x.shape)>2:\n",
    "            im.append(x[channel,:,:])\n",
    "        else:\n",
    "            im.append(x) \n",
    "    return im\n",
    "\n",
    "# evaluate the runs of a method\n",
    "bases=['MslLorNN_','mfold','nnunet','2phase','SwinCa_','scnn25_']\n",
    "bases=['MslDCNN_','MslCENN_']\n",
    "bases=['SwinGw_','nnUNetGw','MslNetNN_Gw','MslLorNN_Gw']\n",
    "bases=['SwinCa_','mfold_','MslLorNN_']\n",
    "bases=['SCNN25_gw','2phase','SwinGw_','MslNetNN_','MslLorNN_']\n",
    "bases=['SCNN25_gw']\n",
    "bases=['SwinCA_','nnUNetCA','MslNetNNCA_','MslLorNNCA_']\n",
    "bases=['SwinGw_','MslNetNN_','MslLorNN_']\n",
    "n=len(tek)\n",
    "nb=len(bases)\n",
    "nclf=4\n",
    "allp=np.zeros((n,nb,nclf))\n",
    "allr=np.zeros((n,nb,nclf))\n",
    "ious=np.zeros((n,nb,nclf))\n",
    "dices=np.zeros((n,nb,nclf))\n",
    "ahds=np.zeros((n,nb,nclf))\n",
    "valid=np.ones((n,nb,nclf),dtype=np.int32)\n",
    "thr=0\n",
    "for s in range(n):\n",
    "    y,dy=load_masks(path,te[tek[s]],'.png')\n",
    "    nr,nc=y[0].shape\n",
    "    for b in range(len(bases)):\n",
    "        base=bases[b]\n",
    "        names=[]\n",
    "        for j in range(nclf):\n",
    "            name='%s%d'%(base,j)\n",
    "            names.append(name)\n",
    "        #names=['nnunet/pred0','nnunet/pred1','nnunet/predf0','nnunet/predf1']\n",
    "        #names=['SCNN25_gw0','SCNN25_gw1','SCNN25_gw3']\n",
    "        #names=['ScrDeliveryDlls_070509']\n",
    "        nclf=len(names)            \n",
    "        for j in range(nclf):\n",
    "            paths=path+'Resultsloc/'+names[j]+'/'\n",
    "            xrs=load_images(paths,te[tek[s]],'.png')\n",
    "            #print(len(xrs))\n",
    "            if len(xrs)==0:\n",
    "                valid[s,b,j]=0\n",
    "                continue\n",
    "            ps=[]\n",
    "            rs=[]\n",
    "            ds=[]\n",
    "            ios=[]\n",
    "            ahd=[]\n",
    "            for i in range(len(xrs)):\n",
    "                xr=xrs[i]\n",
    "                #print(torch.max(xr))\n",
    "                xr=(xr[:nr,:nc]>thr).float()\n",
    "                dx=ndimage.distance_transform_edt(1-xr)\n",
    "                p,r=eval1(dx,dy[i],3)\n",
    "                ds.append(Dice(y[i],xr))\n",
    "                ios.append(iou1(y[i],xr))\n",
    "                ahd.append(AHD(dx,dy[i]))\n",
    "                ps.append(p)\n",
    "                rs.append(r)\n",
    "            allp[s,b,j]=np.mean(ps)\n",
    "            allr[s,b,j]=np.mean(rs)\n",
    "            ious[s,b,j]=np.mean(ios)\n",
    "            dices[s,b,j]=np.mean(ds)\n",
    "            ahds[s,b,j]=np.mean(ahd)\n",
    "            #print(i,j,p,r)\n",
    "    if s%10==0:\n",
    "        p,r=np.mean(allp[:s+1,0,0]),np.mean(allr[:s+1,0,0])\n",
    "        d,io=np.mean(dices[:s+1,0,0]),np.mean(ious[:s+1,0,0])\n",
    "        ahd=np.mean(ahds[:s+1,0,0])\n",
    "        f=2*p*r/(p+r)\n",
    "        print('%d %1.2f %1.2f %1.2f %1.2f %1.2f %.1f'%(s,p*100,r*100,f*100,d*100,io*100,ahd))\n",
    "for b in range(len(bases)):\n",
    "    p,r,f,d,io,ahd=[],[],[],[],[],[]\n",
    "    for j in range(nclf):\n",
    "        name='%s%d'%(bases[b],j)\n",
    "        #name=names[j]\n",
    "        p.append(np.mean(allp[valid[:,b,j]==1,b,j])*100)\n",
    "        r.append(np.mean(allr[valid[:,b,j]==1,b,j])*100)\n",
    "        d.append(np.mean(dices[valid[:,b,j]==1,b,j])*100)\n",
    "        io.append(np.mean(ious[valid[:,b,j]==1,b,j])*100) \n",
    "        ahd.append(np.mean(ahds[(valid[:,b,j]==1)&(np.isnan(ahds[:,b,j])==False),b,j])) \n",
    "        f.append(2*p[j]*r[j]/(p[j]+r[j]))\n",
    "        log2file('evalseq.txt','%s %.2f %1.2f %1.2f %1.2f %1.2f %1.2f %.1f'%(name,thr,p[j],r[j],f[j],d[j],io[j],ahd[j]))\n",
    "    if len(p)>1:\n",
    "        log2file('evalseq.txt','%.2f &%1.2f (%.2f) &%1.2f (%.2f) &%1.2f (%1.2f) &%1.2f (%1.2f) &%1.2f (%1.2f) &%1.1f (%1.1f)'%(thr,np.mean(p),np.std(p),np.mean(r),np.std(r),np.mean(f),np.std(f),np.mean(d),np.std(d),np.mean(io),np.std(io),np.mean(ahd),np.std(ahd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
